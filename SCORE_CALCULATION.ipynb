{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zdV8CN-huTU",
    "outputId": "e881ad2b-ecdf-4056-960c-81febfc88922"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J49JC8KJ-TWR",
    "outputId": "e5c0d6ad-3aaa-4de9-cae7-9ef7c1999a69"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall torchaudio -y\n",
    "# !pip uninstall torchmetrics -y\n",
    "# !pip install torchaudio\n",
    "!pip install torchmetrics==0.11.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a647Y-2HhOvS"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M9W41VQlGTvu",
    "outputId": "bb1faab7-244a-46e2-e770-f93fedf769c2"
   },
   "outputs": [],
   "source": [
    "!pip install summ_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uu1kJNMDphfO",
    "outputId": "38cc2a95-afc6-4606-a39f-484060e7129c"
   },
   "outputs": [],
   "source": [
    "!pip install wmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlH5QvxKDRAm"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class BleuMetric:\n",
    "    def __init__(self, n=4):\n",
    "        self.n = n\n",
    "        self.weights = [1/self.n]*self.n\n",
    "        self.reference_counters = []\n",
    "        self.reference_length = 0\n",
    "\n",
    "    def compute_ngram_counts(self, sentence):\n",
    "        ngram_counts = []\n",
    "        for n in range(1, self.n+1):\n",
    "            ngram_counts.append(Counter(zip(*[sentence[i:] for i in range(n)])))\n",
    "        return ngram_counts\n",
    "\n",
    "    def compute_reference_counters(self, references):\n",
    "        for reference in references:\n",
    "            reference_counters = self.compute_ngram_counts(reference)\n",
    "            self.reference_counters.append(reference_counters)\n",
    "            self.reference_length += len(reference)\n",
    "\n",
    "    def compute_modified_precision(self, hypothesis, reference_counters):\n",
    "        hypothesis_counters = self.compute_ngram_counts(hypothesis)\n",
    "        clipped_counters = []\n",
    "        for i in range(self.n):\n",
    "            clipped_counter = hypothesis_counters[i] & reference_counters[i]\n",
    "            clipped_counters.append(sum(clipped_counter.values()))\n",
    "        hypothesis_length = len(hypothesis)\n",
    "        if hypothesis_length == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            modified_precision = [clipped_counters[i] / hypothesis_length for i in range(self.n)]\n",
    "            return modified_precision\n",
    "\n",
    "    def compute_brevity_penalty(self, hypothesis_length):\n",
    "        if hypothesis_length >= self.reference_length:\n",
    "            return 1\n",
    "        else:\n",
    "            brevity_penalty = math.exp(1 - self.reference_length / hypothesis_length)\n",
    "            return brevity_penalty\n",
    "\n",
    "    def compute_bleu(self, hypotheses, references):\n",
    "        if not self.reference_counters:\n",
    "            self.compute_reference_counters(references)\n",
    "        total_modified_precision = [0]*self.n\n",
    "        total_hypothesis_length = 0\n",
    "        for hypothesis in hypotheses:\n",
    "            hypothesis_length = len(hypothesis)\n",
    "            total_hypothesis_length += hypothesis_length\n",
    "            best_modified_precision = [0]*self.n\n",
    "            for reference_counters in self.reference_counters:\n",
    "                modified_precision = self.compute_modified_precision(hypothesis, reference_counters)\n",
    "                for i in range(self.n):\n",
    "                    best_modified_precision[i] = max(best_modified_precision[i], modified_precision[i])\n",
    "            for i in range(self.n):\n",
    "                total_modified_precision[i] += self.weights[i] * math.log(best_modified_precision[i] + 1e-12)\n",
    "        brevity_penalty = self.compute_brevity_penalty(total_hypothesis_length)\n",
    "        bleu_score = brevity_penalty * math.exp(sum(total_modified_precision))\n",
    "        return bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503,
     "referenced_widgets": [
      "78ddecc6d66a4a8ea53ac8a4da6d781a",
      "75c2123cf2db4bfcb99bba389d88706c",
      "e30074190c12446489af13bd817678d0",
      "d9d19b0b71c344e1af09138f3a504bcc",
      "418e52218cde4f73ba5d3149d1c64dfb",
      "6e56bd4738cc434485e94d5e006cfa4e",
      "a4e1dfd5bb624f788c3e5fae30805360",
      "609ff1eaba784c76867b23c380aa3ad7",
      "b31a1964c42c4f5f8a4e7aaad11ef9f6",
      "c5133d5f0a0a458591dc0fba4dbc4bb4",
      "c41fc26b161b4b7e9fc9bc7ca0c30c5f",
      "ea902354baf245d19a439ec684f57075",
      "869ad6a05ad7463ebabbcca33b5af1a9",
      "63e27b67165447b5aa09761f97920590",
      "db3a32d3d2f24923b83775a30039c2b3",
      "fb768e92a0b84575b8fc5d1389b3fc8f",
      "65f210b9580747ea8136e71c79c4a316",
      "527216c466c046f580a799dc14667159",
      "22a11ece16b6409c9b2eb3b3d502ab9a",
      "e58bca0a2ed94edc9781f4bcf1af216c",
      "0cec3797ee334bccb29e23df8aac2b25",
      "0c9496ce355348f8873c11cdf9d540b5",
      "30949aaa8eab4dc690ec38b6d377e0d1",
      "2e019b974a0240498f5d0ad7d806fda9",
      "ba4ab9e40326418086a5ac56d627e897",
      "13dac0b656fb49ff90558a94feff0d73",
      "3749bdf82e4043a9bbb2ffa5f841845b",
      "f9fdf67e33584bd08bc256e1646aba73",
      "8f07a90ed5734fcab37d961ff6e65cf5",
      "4bb69ef5f49943e88fc4918c206f6437",
      "67f09c08edf54022ac214ee6668a4f15",
      "7cca55e95e644dbc88084a418779f14f",
      "bcd4f513e2a742b5ae864a5ed2622467",
      "e8f23091debd435bb6626cd933e7ef73",
      "67396879750b42cfa0e3eaa56699f496",
      "6e7dc2cb1cbd464b8256b7cd7e65601b",
      "731c16191ca44dcda9236476d0993cfc",
      "4b86f6583b504b45b365f6ffa1aeb95d",
      "31be5e4eb19a4253862f7e7b73d6c747",
      "de6fc86f0a8e4b67a7f0412fa6cb9d1d",
      "1caf32c6c62849ed98d58f40227aa0dc",
      "4a9dbe8be8e84b8881c1e2255f9c3232",
      "b63a07e670714757a8e5c78417450f6e",
      "89094df9e0bf4b0b9e693f94254e1212",
      "d8602f1fce794831b99c6da8625272e1",
      "f15f6a20ecef4157a6ac6b43e5018ab1",
      "3b653efba395479689760e55862aa580",
      "f53a3fddcadc450190927748c3f3b5d9",
      "b7021ff50caf4222b2fab06796217079",
      "23b0a018c6b047c7ae1675441da10cf2",
      "49e4c79685b645b595b74b683d7168de",
      "794250f6a75f47fe8d011cfd3129d42e",
      "88c294fb6c5446eab383c064c39fcbfc",
      "3ffa521ff84a4316a2e0d8520a194a11",
      "0f7398f3cdea4cbeabaeeb03f63e97c7",
      "b74220d7d79b4b73a4d0bbd8f2f6551e",
      "19c8c863a8d94bfe9a0859a921ce1176",
      "fc9461d0b43f44a6bfe8313c86515d5f",
      "bca28d0ba59c474dbb29bb1eb974a973",
      "b18f2f7be61846ebbdb6e60909bc8e87",
      "64e69e3cf41f4f2b9df5fbf7260084f2",
      "f61fd329dbb24a58aff96368155501f9",
      "7b7eae4589b942cb93ad28a8bcbedb7b",
      "fd196656bdfc49d19552208fbed4cc0d",
      "ad1f82f9697347ecb79ae2549a4eaf97",
      "9fcf1abdd7a848e4b43470540792e6ee"
     ]
    },
    "id": "1J-Zpk1iC05u",
    "outputId": "0655ff19-1f55-4c2e-862a-3a02163bb29d"
   },
   "outputs": [],
   "source": [
    "#from summ_eval.rouge_metric import RougeMetric\n",
    "# rouge = RougeMetric()\n",
    "# from sys import exit\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "from summ_eval.bert_score_metric import BertScoreMetric\n",
    "bert_score=BertScoreMetric()\n",
    "\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "blanc_score=BlancMetric()\n",
    "\n",
    "# from summ_eval.mover_score_metric import  MoverScoreMetric\n",
    "# mover_score= MoverScoreMetric()\n",
    "\n",
    "from summ_eval.sentence_movers_metric import SentenceMoversMetric\n",
    "sentence_mover_score=SentenceMoversMetric()\n",
    "\n",
    "from summ_eval.summa_qa_metric import  SummaQAMetric\n",
    "summa_qa_score= SummaQAMetric()\n",
    "\n",
    "# from summ_eval.supert_metric import SupertMetric\n",
    "# supert_score =SupertMetric()\n",
    "\n",
    "from summ_eval.meteor_metric import  MeteorMetric\n",
    "meteor_score =  MeteorMetric()\n",
    "\n",
    "# from summ_eval.s3_metric import S3Metric\n",
    "# s3_metric =S3Metric()\n",
    "\n",
    "# from summ_eval.syntactic_metric import  SyntacticMetric\n",
    "# syntactic_score =SyntacticMetric()\n",
    "\n",
    "from summ_eval.cider_metric import CiderMetric\n",
    "cider_score = CiderMetric()\n",
    "\n",
    "from summ_eval.chrfpp_metric import  ChrfppMetric\n",
    "chrfpp_score= ChrfppMetric()\n",
    "\n",
    "# from summ_eval.bleu_metric import BleuMetric\n",
    "# blue_score_4 = BleuMetric() # BLEU 4\n",
    "# blue_score_4 = BleuMetric(n=4) # BLEU 4\n",
    "# blue_score_3 = BleuMetric(n=3) # BLEU 3\n",
    "# blue_score_2 = BleuMetric(n=2) # BLEU 2\n",
    "# blue_score_1 = BleuMetric(n=1) # BLEU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcbTfLM7GxJ9",
    "outputId": "61c7bdde-4b3d-4702-e86b-319d4d3f6dac"
   },
   "outputs": [],
   "source": [
    "!pip install -U  git+https://github.com/bheinzerling/pyrouge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0qmyZx6G9u9",
    "outputId": "4f150369-5049-4242-ca2a-b879a0ef1599"
   },
   "outputs": [],
   "source": [
    "!export ROUGE_HOME={os.path.join(dirname, \"ROUGE-1.5.5/\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFA240enivxw",
    "outputId": "9d914733-7a3e-4cde-8bb1-f7ca4e972469"
   },
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxluP2LxdRjZ"
   },
   "outputs": [],
   "source": [
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4RpNZCsQ8er",
    "outputId": "5f5d9ef6-6377-41a1-acfd-f7c99560d336"
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XezmqURaNrZj",
    "outputId": "cfaaf9a5-ae1f-4b1e-f14c-0395f8da574c"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def compute_meteor_score(hypotheses, references):\n",
    "\n",
    "    meteor_scores = []\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        # Convert the sentences to lowercase\n",
    "        # ref = str(ref).lower()\n",
    "        # hyp = str(hyp).lower()\n",
    "\n",
    "        # Tokenize the hypothesis sentences\n",
    "        hyps_tokenized = word_tokenize(hyp)\n",
    "\n",
    "        # Tokenize the reference sentences\n",
    "        refs_tokenized = word_tokenize(ref)\n",
    "\n",
    "        # Compute the METEOR score\n",
    "        meteor_score_ = meteor_score([refs_tokenized], hyps_tokenized)\n",
    "\n",
    "        meteor_scores.append(meteor_score_)\n",
    "\n",
    "    # Compute the average METEOR score across the batch\n",
    "    avg_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "    return avg_meteor_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVIo3Lb2TBCw",
    "outputId": "73af4a8e-6a46-4c0e-dcb6-88660030fdaf"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ey-XWUaTSTw",
    "outputId": "ecc29030-4c8d-466c-8f03-6f183198633a"
   },
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-D28YJ5QHaPV",
    "outputId": "43a71db9-2941-4d92-d49e-e51ba11898c9"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/neural-dialogue-metrics/Distinct-N.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyxeRtFdJyVR",
    "outputId": "1f032b28-57ce-4772-ecf3-515415632366"
   },
   "outputs": [],
   "source": [
    "!pip install distinct_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNlJs1xlC9vq"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Evaluate_R(summaries, references,type:str=\"rouge\"):\n",
    "\n",
    "  #summaries- A list of summaries\n",
    "  #references- A list of predicted summaries\n",
    "\n",
    "  if(type==\"rouge\"):\n",
    "    score_dict = rouge.evaluate_batch(summaries, references)\n",
    "\n",
    "  if(type==\"bert_score\"):\n",
    "    score_dict=bert_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"blanc_score\"):\n",
    "    score_dict=blanc_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"mover_score\"):\n",
    "    score_dict=mover_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"sentence_mover_score\"):\n",
    "    score_dict=sentence_mover_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"summa_qa_score\"):\n",
    "    score_dict=summa_qa_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"supert_score\"):\n",
    "    score_dict=supert_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"meteor_score\"):\n",
    "    score_dict=meteor_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"s3_metric\"):\n",
    "    score_dict=s3_metric.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"syntactic_score\"):\n",
    "    score_dict=syntactic_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"cider_score\"):\n",
    "    score_dict=cider_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"chrfpp_score\"):\n",
    "    score_dict=chrfpp_score.evaluate_batch(summaries,references)\n",
    "\n",
    "  if(type==\"blue_score_4\"):\n",
    "    # score_dict=blue_score_4.evaluate_batch(summaries,references)\n",
    "    score_dict = BleuMetric(n=4).compute_bleu(summaries, references)\n",
    "\n",
    "  if(type==\"blue_score_3\"):\n",
    "    # score_dict=blue_score_3.evaluate_batch(summaries,references)\n",
    "    score_dict = BleuMetric(n=3).compute_bleu(summaries, references)\n",
    "\n",
    "  if(type==\"blue_score_2\"):\n",
    "    # score_dict=blue_score_2.evaluate_batch(summaries,references)\n",
    "    score_dict = BleuMetric(n=2).compute_bleu(summaries, references)\n",
    "\n",
    "  if(type==\"blue_score_1\"):\n",
    "    # score_dict=blue_score_1.evaluate_batch(summaries,references)\n",
    "    score_dict = BleuMetric(n=1).compute_bleu(summaries, references)\n",
    "  return score_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47fRDZz_64CA",
    "outputId": "dff6f6a9-7b7b-41a9-dd94-ffe5df3faa3b"
   },
   "outputs": [],
   "source": [
    "!pip install -U torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UECN--RJ9mf0",
    "outputId": "787588ba-c7e7-4be1-9e2a-6f6fe43782d0"
   },
   "outputs": [],
   "source": [
    "!pip list | grep torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1TgkJB_K9Wn",
    "outputId": "58b141ca-f14e-447e-80c3-d9144a591c65"
   },
   "outputs": [],
   "source": [
    "# #########IMP EXCEL TO JSON###############\n",
    "# import pandas as pd\n",
    "\n",
    "# # Path to your Excel file\n",
    "# excel_file = \"/content/convert.xlsx\"\n",
    "\n",
    "# # Read the Excel file into a DataFrame\n",
    "# df = pd.read_excel(excel_file)\n",
    "\n",
    "# # Convert the DataFrame to a JSON object\n",
    "# json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# # Write the JSON object to a file\n",
    "# json_file = \"/content/convert.json\"\n",
    "# with open(json_file, \"w\") as file:\n",
    "#     file.write(json_data)\n",
    "\n",
    "# print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mL3AaN5Aynti",
    "outputId": "b398e1a7-2f49-4177-b3c4-70420483071e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "# from torchtext.vocab import GloVe\n",
    "# glove_vectors = Vectors(name=\"/content/glove.840B.300d.txt\")  # Replace with the path to your GloVe vectors\n",
    "glove_vectors = Vectors(name=\"/content/drive/MyDrive/Resume/glove.42B.300d.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daNTpXPtyqIx"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return sentence.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_DuRse0ytGI"
   },
   "source": [
    "# Embedding Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETUFKAa-ywoR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Calculate the average word embeddings for each sentence\n",
    "def sentence_embedding(sentence, word_vectors):\n",
    "    # words = tokenizer(sentence)\n",
    "    words = tokenize(sentence)\n",
    "    # Convert words to word embeddings and calculate the average\n",
    "    # word_embeddings = [word_vectors.get_vector(word) for word in words if word in word_vectors.stoi]\n",
    "    word_embeddings = [word_vectors.vectors[word_vectors.stoi[word]] for word in words if word in word_vectors.stoi]\n",
    "\n",
    "    if word_embeddings:\n",
    "        return torch.mean(torch.stack(word_embeddings), dim=0)\n",
    "    else:\n",
    "        return torch.zeros(word_vectors.vectors.shape[1])  # Return zeros if no valid word embeddings found\n",
    "\n",
    "# Step 4: Compare sentence-level embeddings to compute the similarity score\n",
    "def embedding_average_similarity(hypothesis, reference, word_vectors):\n",
    "    # Calculate sentence embeddings\n",
    "    hyp_embedding = sentence_embedding(hypothesis, word_vectors)\n",
    "    ref_embedding = sentence_embedding(reference, word_vectors)\n",
    "\n",
    "    # Calculate cosine similarity between the sentence embeddings\n",
    "    similarity_score = F.cosine_similarity(hyp_embedding.unsqueeze(0), ref_embedding.unsqueeze(0))\n",
    "\n",
    "    return similarity_score.item()\n",
    "\n",
    "# # Example usage:\n",
    "# hypothesis_sentence = \"This is an example sentence.\"\n",
    "# reference_sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# similarity_score = embedding_average_similarity(hypothesis_sentence, reference_sentence, glove_vectors)\n",
    "# print(f\"Embedding Average Similarity Score: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DYkE224y3YA"
   },
   "source": [
    "# Embedding Greedy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_54uLowMy2hy"
   },
   "outputs": [],
   "source": [
    "# Step 3: Calculate the cosine similarity between tokens in the reference and hypothesis\n",
    "def greedy_matching_similarity(hypothesis, reference, word_vectors):\n",
    "    # Tokenize both the hypothesis and reference\n",
    "    hyp_tokens = tokenize(hypothesis)\n",
    "    ref_tokens = tokenize(reference)\n",
    "\n",
    "    # Initialize a matrix to store cosine similarity scores\n",
    "    similarity_matrix = torch.zeros((len(ref_tokens), len(hyp_tokens)))\n",
    "\n",
    "    # Calculate cosine similarity for each pair of tokens\n",
    "    for i, ref_token in enumerate(ref_tokens):\n",
    "        for j, hyp_token in enumerate(hyp_tokens):\n",
    "            if ref_token in word_vectors.stoi and hyp_token in word_vectors.stoi:\n",
    "                ref_embedding = word_vectors.vectors[word_vectors.stoi[ref_token]]\n",
    "                hyp_embedding = word_vectors.vectors[word_vectors.stoi[hyp_token]]\n",
    "                similarity = F.cosine_similarity(ref_embedding.unsqueeze(0), hyp_embedding.unsqueeze(0))\n",
    "                similarity_matrix[i][j] = similarity\n",
    "\n",
    "    # Forward direction: Match reference tokens to hypothesis tokens\n",
    "    forward_scores = similarity_matrix.max(dim=1)[0]  # Greedily select the maximum similarity for each reference token\n",
    "    forward_avg_score = forward_scores.mean()\n",
    "\n",
    "    # Reverse direction: Match hypothesis tokens to reference tokens\n",
    "    reverse_scores = similarity_matrix.max(dim=0)[0]  # Greedily select the maximum similarity for each hypothesis token\n",
    "    reverse_avg_score = reverse_scores.mean()\n",
    "\n",
    "    # Take the average of forward and reverse scores to ensure symmetry\n",
    "    aggregate_score = (forward_avg_score + reverse_avg_score) / 2.0\n",
    "\n",
    "    return aggregate_score.item()\n",
    "\n",
    "# # Example usage:\n",
    "# hypothesis_sentence = \"This is an example sentence.\"\n",
    "# reference_sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# similarity_score = greedy_matching_similarity(hypothesis_sentence, reference_sentence, glove_vectors)\n",
    "# print(f\"Greedy Matching Similarity Score: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMseGrqYzDTY"
   },
   "source": [
    "# Embedding Vector Extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jbk2KPEfzAs4"
   },
   "outputs": [],
   "source": [
    "# Step 3: Calculate the Vector Extrema sentence embedding\n",
    "def vector_extrema_embedding(sentence, word_vectors):\n",
    "    words = tokenize(sentence)\n",
    "\n",
    "    # Initialize extrema embedding with zeros\n",
    "    extrema_embedding = torch.zeros(word_vectors.vectors.shape[1])\n",
    "\n",
    "    # Calculate dimension-wise max and min over word embeddings\n",
    "    for dim in range(word_vectors.vectors.shape[1]):\n",
    "        dim_word_embeddings = []\n",
    "        for word in words:\n",
    "            if word in word_vectors.stoi:\n",
    "                dim_word_embeddings.append(word_vectors.vectors[word_vectors.stoi[word]][dim])\n",
    "        if dim_word_embeddings:\n",
    "            max_value = max(dim_word_embeddings)\n",
    "            min_value = min(dim_word_embeddings)\n",
    "            # Use the absolute maximum value between max and min for each dimension\n",
    "            extrema_embedding[dim] = max(max_value, abs(min_value))\n",
    "\n",
    "    return extrema_embedding\n",
    "\n",
    "# Step 4: Calculate cosine similarity between reference and hypothesis sentence embeddings\n",
    "def vector_extrema_similarity(hypothesis, reference, word_vectors):\n",
    "    # Calculate sentence embeddings using Vector Extrema\n",
    "    hyp_embedding = vector_extrema_embedding(hypothesis, word_vectors)\n",
    "    ref_embedding = vector_extrema_embedding(reference, word_vectors)\n",
    "\n",
    "    # Calculate cosine similarity between the sentence embeddings\n",
    "    similarity_score = F.cosine_similarity(hyp_embedding.unsqueeze(0), ref_embedding.unsqueeze(0))\n",
    "\n",
    "    return similarity_score.item()\n",
    "\n",
    "# Example usage:\n",
    "# hypothesis_sentence = \"This is an example sentence.\"\n",
    "# reference_sentence = \"This is a sample sentence.\"\n",
    "\n",
    "# similarity_score = vector_extrema_similarity(hypothesis_sentence, reference_sentence, glove_vectors)\n",
    "# print(f\"Vector Extrema Similarity Score: {similarity_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRkY1yd0c_0A"
   },
   "source": [
    "# New Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsKKFv7ip9Ih"
   },
   "outputs": [],
   "source": [
    "path = \"/content/BART_ep_30mfccs_clip_inTok421024_3e-5_batchS_8_report.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7gUoFe-Ivvv"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(path,'r') as f:\n",
    "  dic = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3K-dM1O7isg",
    "outputId": "91a7906c-e5bf-4958-d5d2-4aaba2c3f40b"
   },
   "outputs": [],
   "source": [
    "print(dic[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBlZibDcFGxJ",
    "outputId": "e8d172f4-97b6-41ff-a565-62456833521f"
   },
   "outputs": [],
   "source": [
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVrhJyErHyCm"
   },
   "outputs": [],
   "source": [
    "summaries = []\n",
    "references = []\n",
    "\n",
    "# for key in dic.keys():\n",
    "#   if('pred' not in dic[key].keys()):\n",
    "#     continue\n",
    "#   summaries.append(dic[key]['pred'])\n",
    "#   references.append(dic[key]['golden'])\n",
    "\n",
    "# for key in dic:\n",
    "#   summaries.append(key['pred'])\n",
    "#   references.append(key['golden'])\n",
    "for i in range(len(dic)):\n",
    "  summaries.append(dic[i].get('Gold_report'))\n",
    "  references.append(dic[i].get('Generated_report'))\n",
    "\n",
    "  # if('pred' not in dic[key].keys()):\n",
    "  #   continue\n",
    "  # summaries.append(dic[key]['pred'])\n",
    "  # references.append(dic[key]['golden'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWDJ435bd0ue",
    "outputId": "1413091d-61d4-4a8c-df3d-306c8db3bb29"
   },
   "outputs": [],
   "source": [
    "print(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPcn-FA6dw4a",
    "outputId": "ed5c5313-f8ed-4a59-b7d1-06cd2d4748fd"
   },
   "outputs": [],
   "source": [
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLrLjOrNAyxM",
    "outputId": "fb827b60-51b4-4afc-c190-02a9bdea6e90"
   },
   "outputs": [],
   "source": [
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32vjduvukdjV",
    "outputId": "a952af86-2c27-4178-9f1c-2376da75c341"
   },
   "outputs": [],
   "source": [
    "# # Calculate BLEU-1 score\n",
    "# bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "# bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0.5, 0.5, 0, 0))\n",
    "# bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0.33, 0.33, 0.33, 0))\n",
    "# bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "# # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "# print(\"\\nBLEU_1: \",bleu1)\n",
    "# print(\"\\nBLEU_2: \",bleu2)\n",
    "# print(\"\\nBLEU_3: \",bleu3)\n",
    "# print(\"\\nBLEU_4: \",bleu4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c__Y5D2L9l1g"
   },
   "outputs": [],
   "source": [
    "# !pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4-w28KGLi2z",
    "outputId": "cda2f78e-9ad0-441f-8cb5-c8b831f4a113"
   },
   "outputs": [],
   "source": [
    "# import torchmetrics\n",
    "from torchmetrics.functional import bleu_score\n",
    "# bleu_score(summaries,references)\n",
    "print(\"torchmetrics bleu: \",bleu_score(summaries,references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTYfhaDIVmf7",
    "outputId": "9823512a-4f63-4f54-f789-238244d85c5c"
   },
   "outputs": [],
   "source": [
    "# score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "score_lists = [\"bert_score\",\"cider_score\"]\n",
    "for value in score_lists:\n",
    "  print(\"The result of :\", value)\n",
    "  print(Evaluate_R(summaries, references,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "An2ybVoK6mrF",
    "outputId": "9224f582-80c3-40ea-9a9a-f67fcb43eefa"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "scores_list=[]\n",
    "total = len(dic)\n",
    "print(total)\n",
    "rouge = Rouge()\n",
    "# Load the generated and reference summaries\n",
    "for entry in dic:\n",
    "  # print(entry)\n",
    "  generated_q= entry[\"Gold_report\"]\n",
    "  # print(generated_q)\n",
    "  reference_q = entry[\"Generated_report\"]\n",
    "\n",
    " # Compute the ROUGE scores\n",
    "\n",
    "  # scores = rouge.get_scores(generated_q, reference_q)\n",
    "  # scores_list.append(scores)\n",
    "  try:\n",
    "    scores = rouge.get_scores(generated_q, reference_q)\n",
    "    scores_list.append(scores)\n",
    "      # Print the scores\n",
    "  except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    continue\n",
    "  # Print the scores\n",
    "  # print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8pxU4UhWdgG",
    "outputId": "f154ecfb-cb22-44b9-dc55-404b797d094d"
   },
   "outputs": [],
   "source": [
    "rouge1_r=0\n",
    "rouge1_p=0\n",
    "rouge1_f=0\n",
    "\n",
    "\n",
    "rouge2_r=0\n",
    "rouge2_p=0\n",
    "rouge2_f=0\n",
    "\n",
    "\n",
    "rougel_r=0\n",
    "rougel_p=0\n",
    "rougel_f=0\n",
    "for item in scores_list:\n",
    "  rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "  rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "  rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "  rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "  rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "  rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "  rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "  rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "  rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "rouge1_r = rouge1_r/total\n",
    "rouge1_p = rouge1_p/total\n",
    "rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "rouge2_r = rouge2_r/total\n",
    "rouge2_p = rouge2_p/total\n",
    "rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "rougel_r = rougel_r/total\n",
    "rougel_p = rougel_p/total\n",
    "rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "print(\"\\n Average scores:\\n\")\n",
    "print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-R72I2_WN5ZA"
   },
   "outputs": [],
   "source": [
    "# print(\"The result of : meteor_score\")\n",
    "# print(compute_meteor_score(summaries, references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PideJtMTHf-V",
    "outputId": "65a38e84-4377-4d8e-9c26-5308a2753935"
   },
   "outputs": [],
   "source": [
    "# from distinct_n import distinct_n\n",
    "from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "print(\"Distinct-2 score:\", distinct_2_score)\n",
    "distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "print(\"Distinct-1 score:\", distinct_1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUgbJyBrr6LB",
    "outputId": "d06f458c-e3c6-495b-9c90-3f86816a3611"
   },
   "outputs": [],
   "source": [
    "# from distinct_n import distinct_n\n",
    "from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "distinct_2_score = distinct_n_corpus_level(references, 2)\n",
    "print(\"Distinct-2 score Gold Questions:\", distinct_2_score)\n",
    "distinct_1_score = distinct_n_corpus_level(references, 1 )\n",
    "print(\"Distinct-1 score Gold Questions:\", distinct_1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Y8SGvxprHdY"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# # result_file = pd.Dataframe(column = [\"\"])\n",
    "# result_file = []\n",
    "\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/New_Inference/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# # filename = \"t5-basecontracross_ChapTOnly_inTok2600_ep_10_NEWInference.json\" #1\n",
    "# # filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "# file_list = glob.glob(path_add+\"*.json\")\n",
    "# # path = path_add+filename\n",
    "# for path in file_list:\n",
    "#   with open(path,'r') as f:\n",
    "#     dic = json.load(f)\n",
    "#   result_dict = {}\n",
    "#   name, _ = os.path.splitext(path)\n",
    "#   name = name.split(\"/\")\n",
    "#   name = name[-1]\n",
    "#   print(name)\n",
    "\n",
    "\n",
    "\n",
    "#   summaries = []\n",
    "#   references = []\n",
    "\n",
    "#   # for key in dic.keys():\n",
    "#   #   if('pred' not in dic[key].keys()):\n",
    "#   #     continue\n",
    "#   #   summaries.append(dic[key]['pred'])\n",
    "#   #   references.append(dic[key]['golden'])\n",
    "\n",
    "#   # for key in dic:\n",
    "#   #   summaries.append(key['pred'])\n",
    "#   #   references.append(key['golden'])\n",
    "#   for i in range(len(dic)):\n",
    "#     summaries.append(dic[i].get('Generated_Question'))\n",
    "#     references.append(dic[i].get('Gold_Question'))\n",
    "\n",
    "#   # Calculate BLEU-1 score\n",
    "#   bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "#   # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "#   # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "#   # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "#   # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "#   print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "#   from torchmetrics.functional import bleu_score\n",
    "#   tm_bleuscore = bleu_score(summaries,references)\n",
    "#   print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "#   bert_cider = []\n",
    "#   # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "#   score_lists = [\"bert_score\",\"cider_score\"]\n",
    "#   for value in score_lists:\n",
    "#     print(\"The result of :\", value)\n",
    "#     print(Evaluate_R(summaries, references,value))\n",
    "#     bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   import json\n",
    "#   from rouge import Rouge\n",
    "\n",
    "\n",
    "#   scores_list=[]\n",
    "#   total = len(dic)\n",
    "#   print(total)\n",
    "#   rouge = Rouge()\n",
    "#   # Load the generated and reference summaries\n",
    "#   for entry in dic:\n",
    "#     # print(entry)\n",
    "#     generated_q= entry[\"Generated_Question\"]\n",
    "#     # print(generated_q)\n",
    "#     reference_q = entry[\"Gold_Question\"]\n",
    "\n",
    "#   # Compute the ROUGE scores\n",
    "\n",
    "#     scores = rouge.get_scores(generated_q, reference_q)\n",
    "#     scores_list.append(scores)\n",
    "#     # Print the scores\n",
    "#     # print(scores)\n",
    "\n",
    "\n",
    "#   rouge1_r=0\n",
    "#   rouge1_p=0\n",
    "#   rouge1_f=0\n",
    "\n",
    "\n",
    "#   rouge2_r=0\n",
    "#   rouge2_p=0\n",
    "#   rouge2_f=0\n",
    "\n",
    "\n",
    "#   rougel_r=0\n",
    "#   rougel_p=0\n",
    "#   rougel_f=0\n",
    "#   for item in scores_list:\n",
    "#     rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "#     rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "#     rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "#     rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "#     rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "#     rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "#     rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "#     rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "#     rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "#   rouge1_r = rouge1_r/total\n",
    "#   rouge1_p = rouge1_p/total\n",
    "#   rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "#   rouge2_r = rouge2_r/total\n",
    "#   rouge2_p = rouge2_p/total\n",
    "#   rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "#   rougel_r = rougel_r/total\n",
    "#   rougel_p = rougel_p/total\n",
    "#   rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "#   print(\"\\n Average scores:\\n\")\n",
    "#   print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "#   print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "#   print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "#   print(\"The result of : meteor_score\")\n",
    "#   meteor = compute_meteor_score(summaries, references)\n",
    "#   print(meteor)\n",
    "\n",
    "#   # from distinct_n import distinct_n\n",
    "#   from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "#   distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "#   print(\"Distinct-2 score:\", distinct_2_score)\n",
    "#   distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "#   print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "#   result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "#                 \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "#                  \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "#                  \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "#                 \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "#                 \"rougel_f\": rougel_f}\n",
    "\n",
    "\n",
    "#   result_file.append(result_dict)\n",
    "#   # print(result_dict)\n",
    "# results = pd.DataFrame(result_file).to_excel(path_add+\"results.xlsx\", index=False)\n",
    "# results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results.tex\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1C8QoU43xfy"
   },
   "outputs": [],
   "source": [
    "# print(result_file)\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqjD7CAGZ-3f"
   },
   "outputs": [],
   "source": [
    "# pip install -U torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxVdXzDaac7H"
   },
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-lV0Zdqahsn"
   },
   "outputs": [],
   "source": [
    "# !pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYS_HbmYGm5N"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import glob\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# # result_file = pd.Dataframe(column = [\"\"])\n",
    "# result_file = []\n",
    "\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/New_Inference/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# # path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "\n",
    "# # filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# # filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "# file_list = glob.glob(path_add+\"*.json\")\n",
    "# # file_list = [path_add+filename]\n",
    "# # path = path_add+filename\n",
    "# for path in file_list:\n",
    "#   with open(path,'r') as f:\n",
    "#     dic = json.load(f)\n",
    "#   result_dict = {}\n",
    "#   name, _ = os.path.splitext(path)\n",
    "#   name = name.split(\"/\")\n",
    "#   name = name[-1]\n",
    "#   print(name)\n",
    "\n",
    "\n",
    "#   summaries = []\n",
    "#   references = []\n",
    "\n",
    "#   # for key in dic.keys():\n",
    "#   #   if('pred' not in dic[key].keys()):\n",
    "#   #     continue\n",
    "#   #   summaries.append(dic[key]['pred'])\n",
    "#   #   references.append(dic[key]['golden'])\n",
    "\n",
    "#   # for key in dic:\n",
    "#   #   summaries.append(key['pred'])\n",
    "#   #   references.append(key['golden'])\n",
    "#   for i in range(len(dic)):\n",
    "#     summaries.append(str(dic[i].get('Generated_Question')))\n",
    "#     references.append(dic[i].get('Gold_Question'))\n",
    "\n",
    "#   # Calculate BLEU-1 score\n",
    "#   bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "#   # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "#   # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "#   # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "#   # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "#   print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "#   from torchmetrics.functional import bleu_score\n",
    "#   tm_bleuscore = bleu_score(summaries,references)\n",
    "#   print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "#   bert_cider = []\n",
    "#   # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "#   score_lists = [\"bert_score\",\"cider_score\"]\n",
    "#   for value in score_lists:\n",
    "#     print(\"The result of :\", value)\n",
    "#     print(Evaluate_R(summaries, references,value))\n",
    "#     bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   import json\n",
    "#   from rouge import Rouge\n",
    "\n",
    "\n",
    "#   scores_list=[]\n",
    "#   total = len(dic)\n",
    "#   print(total)\n",
    "#   rouge = Rouge()\n",
    "#   # Load the generated and reference summaries\n",
    "#   for entry in dic:\n",
    "#     # print(entry)\n",
    "\n",
    "#     if not entry[\"Generated_Question\"].strip() or entry[\"Generated_Question\"]==\".\":\n",
    "#       generated_q= \"NA\"\n",
    "#     else:\n",
    "#       generated_q= entry[\"Generated_Question\"]\n",
    "\n",
    "\n",
    "#     # print(generated_q)\n",
    "#     reference_q = entry[\"Gold_Question\"]\n",
    "\n",
    "#   # Compute the ROUGE scores\n",
    "#     print(\"generated_q\",generated_q)\n",
    "#     scores = rouge.get_scores(generated_q, reference_q)\n",
    "#     scores_list.append(scores)\n",
    "#     # Print the scores\n",
    "#     # print(scores)\n",
    "\n",
    "\n",
    "#   rouge1_r=0\n",
    "#   rouge1_p=0\n",
    "#   rouge1_f=0\n",
    "\n",
    "\n",
    "#   rouge2_r=0\n",
    "#   rouge2_p=0\n",
    "#   rouge2_f=0\n",
    "\n",
    "\n",
    "#   rougel_r=0\n",
    "#   rougel_p=0\n",
    "#   rougel_f=0\n",
    "#   for item in scores_list:\n",
    "#     rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "#     rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "#     rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "#     rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "#     rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "#     rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "#     rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "#     rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "#     rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "#   rouge1_r = rouge1_r/total\n",
    "#   rouge1_p = rouge1_p/total\n",
    "#   rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "#   rouge2_r = rouge2_r/total\n",
    "#   rouge2_p = rouge2_p/total\n",
    "#   rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "#   rougel_r = rougel_r/total\n",
    "#   rougel_p = rougel_p/total\n",
    "#   rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "#   print(\"\\n Average scores:\\n\")\n",
    "#   print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "#   print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "#   print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "#   print(\"The result of : meteor_score\")\n",
    "#   meteor = compute_meteor_score(summaries, references)\n",
    "#   print(meteor)\n",
    "\n",
    "#   # from distinct_n import distinct_n\n",
    "#   from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "#   distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "#   print(\"Distinct-2 score:\", distinct_2_score)\n",
    "#   distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "#   print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "#   # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "#   #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "#   #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "#   #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "#   #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "#   #               \"rougel_f\": rougel_f}\n",
    "\n",
    "#   result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "#                 \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "#                  \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "#                  \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "#                 \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "#                 \"rougel_f\": rougel_f}\n",
    "\n",
    "#   result_file.append(result_dict)\n",
    "#   # print(result_dict)\n",
    "# results = pd.DataFrame(result_file).to_excel(path_add+\"results_temp.xlsx\", index=False)\n",
    "# results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_temp.tex\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gm8bMXK3QWWW"
   },
   "outputs": [],
   "source": [
    "#######################################################################llava####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilSR6tq4V8LJ",
    "outputId": "f24b6dba-b014-4a32-ad4e-69eaffa81160"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/50_qwenlm.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/50_qwenlm.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5890837d67904fe69e6d1a329d7c086f",
      "a81e3619afa94c779313c20a3ff645b0",
      "bb271dd5e9b74bc2acac5ff776fb9d43",
      "8c51633c36e544b783c2083fb4e9cbba",
      "0c073269a1904e84a164b6c050df889d",
      "ea5821c2bf0b468a8cb98ade1334903f",
      "216c484feb42447099365a599926d68e",
      "a26aee3b72034375b074eb9397d810cc",
      "9e475f4ac5c24d4aa15d841de5e5e0d8",
      "e710145526e64cbfa2d4565656393739",
      "d93959281e7a4ca98eaceb88e8181f5b"
     ]
    },
    "id": "sfDK2xMNQbtA",
    "outputId": "af982637-0156-4679-c069-db7f737da479"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/drive/MyDrive/only_report/Model Path\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/drive/MyDrive/only_report/Model Path/BART_ep_50tag_crosstandiaclip_inTok421024_3e-6_batchS_4_report_3e-6.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_report')))\n",
    "    references.append(dic[i].get('Generated_report'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Gold_report\"].strip() or entry[\"Gold_report\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Gold_report\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Generated_report\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"/BART_ep_50tag_crosstandiaclip_inTok421024_3e-6_batchS_4_report_3e-6_score_results.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"/BART_ep_50tag_crosstandiaclip_inTok421024_3e-6_batchS_4_report_3e-6_score_results.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNfzqVk2Qj2v"
   },
   "outputs": [],
   "source": [
    "######################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loQzysz8QWQP"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835,
     "referenced_widgets": [
      "d3b8ab4df8b54fc0a7ea4eff11c65523",
      "308a7cadaf3a43248139005f6bfeb569",
      "79223369ffa34e89b7c307edf6136305",
      "719ff35d951b4cf7acd6fbc5a4472c5b",
      "6b5cd17a23f04a5e9d57b4f3ff7b7001",
      "a3ccfc9025f549be9bd7b09ceb9b3775",
      "e19d4dd7616e4324aa3f772d2a0127df",
      "d7d0f1770d8c4c9e978a52ab909546fd",
      "f9874de0674d430a89c00cd0a07fc0a5",
      "3c59c7f18707427e9ea28041cb6d406b",
      "5ba215e7d97644fc8e5a1c5e5973bf5d"
     ]
    },
    "id": "quAcVxkrFcbu",
    "outputId": "9a92720a-4881-466e-ea32-ed49ffd20815"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Gold_meme_cap\"].strip() or entry[\"Gold_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Gold_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Generated_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh8gwnPuWwqO",
    "outputId": "9ef7cd9b-50ab-4b18-8d7e-8c31ca247d61"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_obs.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_obs.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EV6uJJoHW0CH",
    "outputId": "bd4a069b-eab4-493c-a15f-20b79441c6d6"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_obs.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_obs.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_obs.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X44zRyQCXA-C",
    "outputId": "15fe2488-72fc-469c-d8e0-2676feaae5c7"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_dep.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_dep.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyUUtYIaXHS8",
    "outputId": "a6920036-e5bb-4ced-cbe2-3cf64c291928"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_dep.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_dep.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_dep.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ldf9x9CFXQCd",
    "outputId": "6f3aaafa-8859-4bb3-d269-8fed7e38b47f"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_slp.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_slp.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZ9oizsJXVLp",
    "outputId": "7735f29c-52c2-4b5b-b574-b07849bfe1d3"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_slp.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_slp.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_slp.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b0Q4Y63GyXi",
    "outputId": "40bca6c1-6165-42c1-fb68-8ffd4df67382"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_wp.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_wp.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ywiEexTXffJ",
    "outputId": "382ea39f-687d-4405-be10-64c2baae88d0"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_wp.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_wp.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_wp.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJsWeXDYVN5k",
    "outputId": "30918515-7676-4f70-aa5e-294f31dddd08"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_old.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_old.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OI8OSsjUVOJm",
    "outputId": "23886b0a-378f-434f-aed4-25f72a812554"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_old.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_old.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_old.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PeVtpAhwVmP9",
    "outputId": "316f6881-ec72-449d-a30b-48e6e8067d4b"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_old_dep.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_old_dep.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYu9qVdWVmZn",
    "outputId": "77c1b904-b327-4134-b931-8a86b13658d4"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_old_dep.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_old_dep.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_old_dep.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNmA86oHV1zT",
    "outputId": "40422786-ea68-4607-a8d1-4ba51eebf76a"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_old_obs.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_old_obs.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjBnRM6pV167",
    "outputId": "02dec4e2-e5db-450c-a89e-209ec83bb80f"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_old_obs.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_old_obs.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_old_obs.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knIWfpLPWDJc",
    "outputId": "4dc2ca82-c0e6-4abe-f7b1-93b1f445da9d"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_old_slp.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_old_slp.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mvFitWNWDSz",
    "outputId": "9b61079c-f0c8-4ae7-fb5f-7179764827e7"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_old_slp.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_old_slp.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_old_slp.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6mACeCZWOi1",
    "outputId": "06768442-989d-4250-9f1b-4decadaadfff"
   },
   "outputs": [],
   "source": [
    "#########IMP EXCEL TO JSON###############\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "excel_file = \"/content/MeSum_old_wp.xlsx\"\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Convert the DataFrame to a JSON object\n",
    "json_data = df.to_json(orient=\"records\")\n",
    "\n",
    "# Write the JSON object to a file\n",
    "json_file = \"/content/MeSum_old_wp.json\"\n",
    "with open(json_file, \"w\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Excel file converted to JSON. JSON file saved as:\", json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dd2dZ6LWOpw",
    "outputId": "a2126132-32fd-448b-e93a-52a61ebf41e0"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/MeSum_old_wp.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_meme_cap')))\n",
    "    references.append(dic[i].get('Generated_meme_cap'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_meme_cap\"].strip() or entry[\"Generated_meme_cap\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_meme_cap\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_meme_cap\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_old_wp.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_old_wp.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfWDo6UzX84E",
    "outputId": "bb572dcb-8f88-4c0b-cf78-3382b040afc1"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/meme_gemini_gptv4_wp.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('meme_caption')))\n",
    "    references.append(dic[i].get('GPTV4'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"GPTV4\"].strip() or entry[\"GPTV4\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"GPTV4\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"meme_caption\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_GPTV4_WP_temp.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_GPTV4_WP_temp.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTByQUdJYFju",
    "outputId": "d0d60871-6097-464a-df2a-73975c491da4"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/meme_gemini_gptv4_slp.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('meme_caption')))\n",
    "    references.append(dic[i].get('GPTV4'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"GPTV4\"].strip() or entry[\"GPTV4\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"GPTV4\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"meme_caption\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"results_GPTV4_SLP_temp.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"results_GPTV4_SLP_temp.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIyZ7GvxYQev"
   },
   "outputs": [],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "average_metric =[]\n",
    "greedy_metric =[]\n",
    "extrema_metric =[]\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "# result_file = pd.Dataframe(column = [\"\"])\n",
    "result_file = []\n",
    "\n",
    "path_add = \"/content/drive/MyDrive/only_report/Model Path/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/final_jsons/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlyt5/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/temp/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/onlybart/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/bs2/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/check/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/falcon/\"\n",
    "\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_embedd/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/ve_embmtrcs/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/video_dependent/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/oldsumm/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt_turbo/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/t5_final/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/categories/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/gpt4/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/vqg_baseline_finetuned/\"\n",
    "# path_add = \"/content/drive/MyDrive/VideoQG/Model Path/Haadia/Model Path/flant5/\"\n",
    "\n",
    "# filename = \"t5-baseTrans_inTok2600_ep_50_NEWInference.json\" #1\n",
    "# filename = \"BART_ep_50_OUT_1024_Inference_NER_FIL_Img_cap_VTitle_NoTrans_inTok2600_Haad_Inference.json\" #2\n",
    "file_list = glob.glob(\"/content/drive/MyDrive/anas/only_report/Model Path/BART_ep_20tag_crosstandiaclip_inTok421024_3e-5_batchS_12_report.json\")\n",
    "# file_list = [path_add+filename]\n",
    "# path = path_add+filename\n",
    "for path in file_list:\n",
    "  with open(path,'r') as f:\n",
    "    print(path)\n",
    "    dic = json.load(f)\n",
    "  result_dict = {}\n",
    "  name, _ = os.path.splitext(path)\n",
    "  name = name.split(\"/\")\n",
    "  name = name[-1]\n",
    "  print(name)\n",
    "\n",
    "\n",
    "  summaries = []\n",
    "  references = []\n",
    "\n",
    "  # for key in dic.keys():\n",
    "  #   if('pred' not in dic[key].keys()):\n",
    "  #     continue\n",
    "  #   summaries.append(dic[key]['pred'])\n",
    "  #   references.append(dic[key]['golden'])\n",
    "\n",
    "  # for key in dic:\n",
    "  #   summaries.append(key['pred'])\n",
    "  #   references.append(key['golden'])\n",
    "  for i in range(len(dic)):\n",
    "    summaries.append(str(dic[i].get('Gold_report')))\n",
    "    references.append(dic[i].get('Generated_report'))\n",
    "\n",
    "  # Calculate BLEU-1 score\n",
    "  bleu1 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(1.0, 0, 0, 0))\n",
    "  # bleu2 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 1.0, 0, 0))\n",
    "  # bleu3 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 1.0, 0))\n",
    "  # bleu4 = nltk.translate.bleu_score.corpus_bleu(references, summaries, weights=(0, 0, 0, 1.0))\n",
    "  # bleu1 = nltk.translate.bleu_score.corpus_bleu(references, references, weights=(1.0, 0, 0, 0))\n",
    "  print(\"\\nBLEU_1: \",bleu1)\n",
    "\n",
    "  from torchmetrics.functional import bleu_score\n",
    "  tm_bleuscore = bleu_score(summaries,references)\n",
    "  print(\"torchmetrics bleu: \",tm_bleuscore)\n",
    "\n",
    "  bert_cider = []\n",
    "  # score_lists = [\"bert_score\",\"cider_score\", \"blue_score_4\",\"blue_score_3\",\"blue_score_2\",\"blue_score_1\"]\n",
    "  score_lists = [\"bert_score\",\"cider_score\"]\n",
    "  for value in score_lists:\n",
    "    print(\"The result of :\", value)\n",
    "    # print(Evaluate_R(summaries, references,value))\n",
    "    bert_cider.append(Evaluate_R(summaries, references,value))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  import json\n",
    "  from rouge import Rouge\n",
    "\n",
    "\n",
    "  scores_list=[]\n",
    "  total = len(dic)\n",
    "  print(total)\n",
    "  rouge = Rouge()\n",
    "  # Load the generated and reference summaries\n",
    "  for entry in dic:\n",
    "    # print(entry)\n",
    "\n",
    "    if not entry[\"Generated_report\"].strip() or entry[\"Generated_report\"]==\".\":\n",
    "      generated_q= \"NA\"\n",
    "    else:\n",
    "      generated_q= entry[\"Generated_report\"]\n",
    "\n",
    "\n",
    "\n",
    "    # print(generated_q)\n",
    "    try:\n",
    "      reference_q = entry[\"Gold_report\"]\n",
    "      average_metric.append(embedding_average_similarity(generated_q, reference_q, glove_vectors))\n",
    "      greedy_metric.append(greedy_matching_similarity(generated_q, reference_q, glove_vectors))\n",
    "      extrema_metric.append(vector_extrema_similarity(generated_q, reference_q, glove_vectors))\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "  # Compute the ROUGE scores\n",
    "    # print(\"generated_q\",generated_q)\n",
    "    # scores = rouge.get_scores(generated_q, reference_q)\n",
    "    # scores_list.append(scores)\n",
    "    try:\n",
    "      scores = rouge.get_scores(generated_q, reference_q)\n",
    "      scores_list.append(scores)\n",
    "    # Print the scores\n",
    "    except Exception as e:\n",
    "      print(\"Error:\", e)\n",
    "      continue\n",
    "    # Print the scores\n",
    "    # print(scores)\n",
    "\n",
    "\n",
    "  rouge1_r=0\n",
    "  rouge1_p=0\n",
    "  rouge1_f=0\n",
    "\n",
    "\n",
    "  rouge2_r=0\n",
    "  rouge2_p=0\n",
    "  rouge2_f=0\n",
    "\n",
    "\n",
    "  rougel_r=0\n",
    "  rougel_p=0\n",
    "  rougel_f=0\n",
    "  for item in scores_list:\n",
    "    rouge1_r=item[0][\"rouge-1\"][\"r\"] + rouge1_r\n",
    "    rouge1_p=item[0][\"rouge-1\"][\"p\"] + rouge1_p\n",
    "    rouge1_f=item[0][\"rouge-1\"][\"f\"] + rouge1_f\n",
    "\n",
    "\n",
    "    rouge2_r=item[0][\"rouge-2\"][\"r\"] + rouge2_r\n",
    "    rouge2_p=item[0][\"rouge-2\"][\"p\"] + rouge2_p\n",
    "    rouge2_f=item[0][\"rouge-2\"][\"f\"] + rouge2_f\n",
    "\n",
    "\n",
    "    rougel_r=item[0][\"rouge-l\"][\"r\"] + rougel_r\n",
    "    rougel_p=item[0][\"rouge-l\"][\"p\"] + rougel_p\n",
    "    rougel_f=item[0][\"rouge-l\"][\"f\"] + rougel_f\n",
    "\n",
    "\n",
    "  rouge1_r = rouge1_r/total\n",
    "  rouge1_p = rouge1_p/total\n",
    "  rouge1_f = rouge1_f/total\n",
    "\n",
    "\n",
    "  rouge2_r = rouge2_r/total\n",
    "  rouge2_p = rouge2_p/total\n",
    "  rouge2_f = rouge2_f/total\n",
    "\n",
    "\n",
    "  rougel_r = rougel_r/total\n",
    "  rougel_p = rougel_p/total\n",
    "  rougel_f = rougel_f/total\n",
    "\n",
    "\n",
    "  print(\"\\n Average scores:\\n\")\n",
    "  print(\"rouge-1 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge1_r,rouge1_p,rouge1_f))\n",
    "  print(\"\\nrouge-2 : \\t recal: {}, precision: {}, fscore: {}\".format(rouge2_r,rouge2_p,rouge2_f))\n",
    "  print(\"\\nrouge-l : \\t recal: {}, precision: {}, fscore: {}\".format(rougel_r,rougel_p,rougel_f))\n",
    "\n",
    "\n",
    "\n",
    "  print(\"The result of : meteor_score\")\n",
    "  meteor = compute_meteor_score(summaries, references)\n",
    "  print(meteor)\n",
    "\n",
    "  # from distinct_n import distinct_n\n",
    "  from distinct_n.metrics import *\n",
    "\n",
    "\n",
    "  distinct_2_score = distinct_n_corpus_level(summaries, 2)\n",
    "  print(\"Distinct-2 score:\", distinct_2_score)\n",
    "  distinct_1_score = distinct_n_corpus_level(summaries, 1 )\n",
    "  print(\"Distinct-1 score:\", distinct_1_score)\n",
    "\n",
    "  # result_dict = {\"Model\": name, \"nltk_bleu1\": bleu1, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "  #               \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "  #                \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "  #                \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "  #               \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "  #               \"rougel_f\": rougel_f}\n",
    "\n",
    "  result_dict = {\"Model\": name, \"tm_bleu\": tm_bleuscore.numpy().tolist(),\"cider\": bert_cider[1]['cider'],\"Meteor\": meteor,\n",
    "                \"Distinct1\": distinct_1_score,\"Distinct2\": distinct_2_score,\"bert_P\": bert_cider[0]['bert_score_precision'],\n",
    "                 \"bert_R\": bert_cider[0]['bert_score_recall'], \"bert_F1\": bert_cider[0]['bert_score_f1'],\n",
    "                 \"rouge1_r\" :rouge1_r, \"rouge1_p\": rouge1_p, \"rouge1_f\": rouge1_f,\n",
    "                \"rouge2_r\": rouge2_r, \"rouge2_p\": rouge2_p, \"rouge2_f\": rouge2_f, \"rougel_r\": rougel_r, \"rougel_p\": rougel_p,\n",
    "                \"rougel_f\": rougel_f, \"Embd_Avg\": Average(average_metric) , \"Embd_Grdy\": Average(greedy_metric), \"Embd_Extrm\": Average(extrema_metric)}\n",
    "\n",
    "  result_file.append(result_dict)\n",
    "  print(result_dict)\n",
    "results = pd.DataFrame(result_file).to_excel(path_add+\"BART_ep_50tag_crosstandiaclip_inTok421024_3e-6_batchS_4_report_3e-6_scores.xlsx\", index=False)\n",
    "results_tex = pd.DataFrame(result_file).to_latex(path_add+\"BART_ep_50tag_crosstandiaclip_inTok421024_3e-6_batchS_4_report_3e-6_scores.tex\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c073269a1904e84a164b6c050df889d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c9496ce355348f8873c11cdf9d540b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0cec3797ee334bccb29e23df8aac2b25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f7398f3cdea4cbeabaeeb03f63e97c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13dac0b656fb49ff90558a94feff0d73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cca55e95e644dbc88084a418779f14f",
      "placeholder": "​",
      "style": "IPY_MODEL_bcd4f513e2a742b5ae864a5ed2622467",
      "value": " 466k/466k [00:00&lt;00:00, 5.39MB/s]"
     }
    },
    "19c8c863a8d94bfe9a0859a921ce1176": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64e69e3cf41f4f2b9df5fbf7260084f2",
      "placeholder": "​",
      "style": "IPY_MODEL_f61fd329dbb24a58aff96368155501f9",
      "value": "model.safetensors: 100%"
     }
    },
    "1caf32c6c62849ed98d58f40227aa0dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "216c484feb42447099365a599926d68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22a11ece16b6409c9b2eb3b3d502ab9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23b0a018c6b047c7ae1675441da10cf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e019b974a0240498f5d0ad7d806fda9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9fdf67e33584bd08bc256e1646aba73",
      "placeholder": "​",
      "style": "IPY_MODEL_8f07a90ed5734fcab37d961ff6e65cf5",
      "value": "tokenizer.json: 100%"
     }
    },
    "308a7cadaf3a43248139005f6bfeb569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3ccfc9025f549be9bd7b09ceb9b3775",
      "placeholder": "​",
      "style": "IPY_MODEL_e19d4dd7616e4324aa3f772d2a0127df",
      "value": "model.safetensors: 100%"
     }
    },
    "30949aaa8eab4dc690ec38b6d377e0d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e019b974a0240498f5d0ad7d806fda9",
       "IPY_MODEL_ba4ab9e40326418086a5ac56d627e897",
       "IPY_MODEL_13dac0b656fb49ff90558a94feff0d73"
      ],
      "layout": "IPY_MODEL_3749bdf82e4043a9bbb2ffa5f841845b"
     }
    },
    "31be5e4eb19a4253862f7e7b73d6c747": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3749bdf82e4043a9bbb2ffa5f841845b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b653efba395479689760e55862aa580": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_794250f6a75f47fe8d011cfd3129d42e",
      "max": 443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88c294fb6c5446eab383c064c39fcbfc",
      "value": 443
     }
    },
    "3c59c7f18707427e9ea28041cb6d406b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ffa521ff84a4316a2e0d8520a194a11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "418e52218cde4f73ba5d3149d1c64dfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49e4c79685b645b595b74b683d7168de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a9dbe8be8e84b8881c1e2255f9c3232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b86f6583b504b45b365f6ffa1aeb95d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bb69ef5f49943e88fc4918c206f6437": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527216c466c046f580a799dc14667159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5890837d67904fe69e6d1a329d7c086f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a81e3619afa94c779313c20a3ff645b0",
       "IPY_MODEL_bb271dd5e9b74bc2acac5ff776fb9d43",
       "IPY_MODEL_8c51633c36e544b783c2083fb4e9cbba"
      ],
      "layout": "IPY_MODEL_0c073269a1904e84a164b6c050df889d"
     }
    },
    "5ba215e7d97644fc8e5a1c5e5973bf5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "609ff1eaba784c76867b23c380aa3ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63e27b67165447b5aa09761f97920590": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22a11ece16b6409c9b2eb3b3d502ab9a",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e58bca0a2ed94edc9781f4bcf1af216c",
      "value": 231508
     }
    },
    "64e69e3cf41f4f2b9df5fbf7260084f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65f210b9580747ea8136e71c79c4a316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67396879750b42cfa0e3eaa56699f496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31be5e4eb19a4253862f7e7b73d6c747",
      "placeholder": "​",
      "style": "IPY_MODEL_de6fc86f0a8e4b67a7f0412fa6cb9d1d",
      "value": "config.json: 100%"
     }
    },
    "67f09c08edf54022ac214ee6668a4f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b5cd17a23f04a5e9d57b4f3ff7b7001": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e56bd4738cc434485e94d5e006cfa4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e7dc2cb1cbd464b8256b7cd7e65601b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1caf32c6c62849ed98d58f40227aa0dc",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a9dbe8be8e84b8881c1e2255f9c3232",
      "value": 570
     }
    },
    "719ff35d951b4cf7acd6fbc5a4472c5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c59c7f18707427e9ea28041cb6d406b",
      "placeholder": "​",
      "style": "IPY_MODEL_5ba215e7d97644fc8e5a1c5e5973bf5d",
      "value": " 440M/440M [00:03&lt;00:00, 134MB/s]"
     }
    },
    "731c16191ca44dcda9236476d0993cfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b63a07e670714757a8e5c78417450f6e",
      "placeholder": "​",
      "style": "IPY_MODEL_89094df9e0bf4b0b9e693f94254e1212",
      "value": " 570/570 [00:00&lt;00:00, 12.5kB/s]"
     }
    },
    "75c2123cf2db4bfcb99bba389d88706c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e56bd4738cc434485e94d5e006cfa4e",
      "placeholder": "​",
      "style": "IPY_MODEL_a4e1dfd5bb624f788c3e5fae30805360",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "78ddecc6d66a4a8ea53ac8a4da6d781a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75c2123cf2db4bfcb99bba389d88706c",
       "IPY_MODEL_e30074190c12446489af13bd817678d0",
       "IPY_MODEL_d9d19b0b71c344e1af09138f3a504bcc"
      ],
      "layout": "IPY_MODEL_418e52218cde4f73ba5d3149d1c64dfb"
     }
    },
    "79223369ffa34e89b7c307edf6136305": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7d0f1770d8c4c9e978a52ab909546fd",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9874de0674d430a89c00cd0a07fc0a5",
      "value": 440449768
     }
    },
    "794250f6a75f47fe8d011cfd3129d42e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b7eae4589b942cb93ad28a8bcbedb7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cca55e95e644dbc88084a418779f14f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "869ad6a05ad7463ebabbcca33b5af1a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65f210b9580747ea8136e71c79c4a316",
      "placeholder": "​",
      "style": "IPY_MODEL_527216c466c046f580a799dc14667159",
      "value": "vocab.txt: 100%"
     }
    },
    "88c294fb6c5446eab383c064c39fcbfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "89094df9e0bf4b0b9e693f94254e1212": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c51633c36e544b783c2083fb4e9cbba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e710145526e64cbfa2d4565656393739",
      "placeholder": "​",
      "style": "IPY_MODEL_d93959281e7a4ca98eaceb88e8181f5b",
      "value": " 440M/440M [00:03&lt;00:00, 158MB/s]"
     }
    },
    "8f07a90ed5734fcab37d961ff6e65cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e475f4ac5c24d4aa15d841de5e5e0d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9fcf1abdd7a848e4b43470540792e6ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a26aee3b72034375b074eb9397d810cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3ccfc9025f549be9bd7b09ceb9b3775": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e1dfd5bb624f788c3e5fae30805360": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a81e3619afa94c779313c20a3ff645b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea5821c2bf0b468a8cb98ade1334903f",
      "placeholder": "​",
      "style": "IPY_MODEL_216c484feb42447099365a599926d68e",
      "value": "model.safetensors: 100%"
     }
    },
    "ad1f82f9697347ecb79ae2549a4eaf97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18f2f7be61846ebbdb6e60909bc8e87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b31a1964c42c4f5f8a4e7aaad11ef9f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b63a07e670714757a8e5c78417450f6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7021ff50caf4222b2fab06796217079": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b74220d7d79b4b73a4d0bbd8f2f6551e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19c8c863a8d94bfe9a0859a921ce1176",
       "IPY_MODEL_fc9461d0b43f44a6bfe8313c86515d5f",
       "IPY_MODEL_bca28d0ba59c474dbb29bb1eb974a973"
      ],
      "layout": "IPY_MODEL_b18f2f7be61846ebbdb6e60909bc8e87"
     }
    },
    "ba4ab9e40326418086a5ac56d627e897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bb69ef5f49943e88fc4918c206f6437",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67f09c08edf54022ac214ee6668a4f15",
      "value": 466062
     }
    },
    "bb271dd5e9b74bc2acac5ff776fb9d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a26aee3b72034375b074eb9397d810cc",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e475f4ac5c24d4aa15d841de5e5e0d8",
      "value": 440449768
     }
    },
    "bca28d0ba59c474dbb29bb1eb974a973": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad1f82f9697347ecb79ae2549a4eaf97",
      "placeholder": "​",
      "style": "IPY_MODEL_9fcf1abdd7a848e4b43470540792e6ee",
      "value": " 1.34G/1.34G [00:10&lt;00:00, 114MB/s]"
     }
    },
    "bcd4f513e2a742b5ae864a5ed2622467": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c41fc26b161b4b7e9fc9bc7ca0c30c5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5133d5f0a0a458591dc0fba4dbc4bb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3b8ab4df8b54fc0a7ea4eff11c65523": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_308a7cadaf3a43248139005f6bfeb569",
       "IPY_MODEL_79223369ffa34e89b7c307edf6136305",
       "IPY_MODEL_719ff35d951b4cf7acd6fbc5a4472c5b"
      ],
      "layout": "IPY_MODEL_6b5cd17a23f04a5e9d57b4f3ff7b7001"
     }
    },
    "d7d0f1770d8c4c9e978a52ab909546fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8602f1fce794831b99c6da8625272e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f15f6a20ecef4157a6ac6b43e5018ab1",
       "IPY_MODEL_3b653efba395479689760e55862aa580",
       "IPY_MODEL_f53a3fddcadc450190927748c3f3b5d9"
      ],
      "layout": "IPY_MODEL_b7021ff50caf4222b2fab06796217079"
     }
    },
    "d93959281e7a4ca98eaceb88e8181f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9d19b0b71c344e1af09138f3a504bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5133d5f0a0a458591dc0fba4dbc4bb4",
      "placeholder": "​",
      "style": "IPY_MODEL_c41fc26b161b4b7e9fc9bc7ca0c30c5f",
      "value": " 48.0/48.0 [00:00&lt;00:00, 1.12kB/s]"
     }
    },
    "db3a32d3d2f24923b83775a30039c2b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cec3797ee334bccb29e23df8aac2b25",
      "placeholder": "​",
      "style": "IPY_MODEL_0c9496ce355348f8873c11cdf9d540b5",
      "value": " 232k/232k [00:00&lt;00:00, 2.62MB/s]"
     }
    },
    "de6fc86f0a8e4b67a7f0412fa6cb9d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e19d4dd7616e4324aa3f772d2a0127df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e30074190c12446489af13bd817678d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_609ff1eaba784c76867b23c380aa3ad7",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b31a1964c42c4f5f8a4e7aaad11ef9f6",
      "value": 48
     }
    },
    "e58bca0a2ed94edc9781f4bcf1af216c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e710145526e64cbfa2d4565656393739": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f23091debd435bb6626cd933e7ef73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67396879750b42cfa0e3eaa56699f496",
       "IPY_MODEL_6e7dc2cb1cbd464b8256b7cd7e65601b",
       "IPY_MODEL_731c16191ca44dcda9236476d0993cfc"
      ],
      "layout": "IPY_MODEL_4b86f6583b504b45b365f6ffa1aeb95d"
     }
    },
    "ea5821c2bf0b468a8cb98ade1334903f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea902354baf245d19a439ec684f57075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_869ad6a05ad7463ebabbcca33b5af1a9",
       "IPY_MODEL_63e27b67165447b5aa09761f97920590",
       "IPY_MODEL_db3a32d3d2f24923b83775a30039c2b3"
      ],
      "layout": "IPY_MODEL_fb768e92a0b84575b8fc5d1389b3fc8f"
     }
    },
    "f15f6a20ecef4157a6ac6b43e5018ab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23b0a018c6b047c7ae1675441da10cf2",
      "placeholder": "​",
      "style": "IPY_MODEL_49e4c79685b645b595b74b683d7168de",
      "value": "config.json: 100%"
     }
    },
    "f53a3fddcadc450190927748c3f3b5d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ffa521ff84a4316a2e0d8520a194a11",
      "placeholder": "​",
      "style": "IPY_MODEL_0f7398f3cdea4cbeabaeeb03f63e97c7",
      "value": " 443/443 [00:00&lt;00:00, 8.26kB/s]"
     }
    },
    "f61fd329dbb24a58aff96368155501f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9874de0674d430a89c00cd0a07fc0a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9fdf67e33584bd08bc256e1646aba73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb768e92a0b84575b8fc5d1389b3fc8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc9461d0b43f44a6bfe8313c86515d5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b7eae4589b942cb93ad28a8bcbedb7b",
      "max": 1340622760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd196656bdfc49d19552208fbed4cc0d",
      "value": 1340622760
     }
    },
    "fd196656bdfc49d19552208fbed4cc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
